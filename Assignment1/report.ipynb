{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "### what we will cover\n",
    "\n",
    "### how we validate\n",
    "\n",
    "### how we measure improvements\n",
    "\n",
    "flops\n",
    "\n",
    "### run commands and flags?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Stupid implementation\n",
    "\n",
    "\n",
    "### python\n",
    "\n",
    "```python\n",
    "start = monotonic()\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        for k in range(N):\n",
    "            C[i][j] += A[i][k] * B[k][j]\n",
    "\n",
    "```\n",
    "\n",
    "average gflops: 0.015153\n",
    "N: 256\n",
    "\n",
    "\n",
    "### cpp\n",
    "\n",
    "```cpp\n",
    "void gemm_stupid(){\n",
    "    for (int i = 0; i < N; i++)\n",
    "        for (int j = 0; j < N; j++) {\n",
    "            for (int k = 0; k < N; k++)\n",
    "                C[i][j] += A[i][k] * B[k][j];\n",
    "        }\n",
    "}\n",
    "```\n",
    "\n",
    "average gflops: 3.738789\n",
    "N: 256\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# numpy (single threaded)\n",
    "\n",
    "We use the library threadpoolctl to force numpy into only using a single thread as shown below.\n",
    "\n",
    "```python\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "with threadpool_limits(limits=1):\n",
    "    pass\n",
    "```\n",
    "\n",
    "We use numpys `@`operator to do the matrix multiplication\n",
    "\n",
    "```python\n",
    "def gemm():\n",
    "    return A @ B\n",
    "```\n",
    "\n",
    "average gflops: 43.073460\n",
    "N: 2048\n",
    "\n",
    "# numpy (multi threaded)\n",
    "\n",
    "numpy by default is multithreaded so we will be testing out how good default numpy is.\n",
    "\n",
    "We get an average gflops of 138, which is impressive but numpy can do much better.\n",
    "Something very important to note is the way we generate the initial matrcies,\n",
    "more importantly their byte sizes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'pygments'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.random.random((N, N))\n",
    "B = np.random.random((N, N))\n",
    "\n",
    "print(A.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can observe that numpys default array type is float64,\n",
    "wich means that we can save up on alot of memory by converging these to float32,\n",
    "squizzing numpy to its best performence.\n",
    "\n",
    "We do the same test as above but with\n",
    "\n",
    "```python\n",
    "A = np.random.random((N, N)).astype(np.float32)\n",
    "B = np.random.random((N, N)).astype(np.float32)\n",
    "```\n",
    "\n",
    "This gives us an impressive average of 390.94 - impressive!\n",
    "\n",
    "We will be using this number as reference since c++ float is float32 by default (other wise double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will circle back to the cpp implemetation and try to achieve the high preformace of numpy,\n",
    "and even beat it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Transposing \n",
    "\n",
    "\n",
    "```cpp\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "- why transposing will help with memory\n",
    "\n",
    "- our findings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d vs 1D arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Blocking\n",
    "\n",
    "## why does blocking even help? (images and memory)\n",
    "\n",
    "### theoretical best based on cache size\n",
    "\n",
    "## testing best \n",
    "\n",
    "We tested the variante that has **threading** and **transposing**\n",
    "- Threading\n",
    "- Transposed\n",
    "\n",
    "| blockSize                              | Matrix Size | FLOP/s\n",
    "|------------------------------------------|-------------|----------------\n",
    "| 4                                 | 1024        | 101.024773 GFLOPS\n",
    "| 8                                 | 1024        | 63.231953 GFLOPS\n",
    "| 16                                | 2048        | 194.324829 GFLOPS\n",
    "| 32                                | 1024        | 94.407333 GFLOPS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading with OMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Unrolling\n",
    "\n",
    "Unrolling is very nice idea that will help us remove the inner most loop by unrolling it.\n",
    "\n",
    "- doing the if statement logic (compiler wise) is expensive\n",
    "\n",
    "\n",
    "our currentl inner loop looks like this\n",
    "```cpp\n",
    "..\n",
    "for (j = 0; j < blockSize; j++) \n",
    "    for (k = 0; k < blockSize; k++){\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k] * B_trans[bj + j][bk + k];\n",
    "    }\n",
    "..\n",
    "\n",
    "```\n",
    "\n",
    "We have an issue where the inner most if loop is being updated for each entry of `k`\n",
    "and this is expensive since the compiler needs to do extra work, and extra memory usage is done here to fetch and upate `k`\n",
    "\n",
    "we can reduce this workload by unrolling `x` amount of instruciont and writing them down manually.\n",
    "\n",
    "for example unrolling by 4 instrucionts would look like this\n",
    "\n",
    "```cpp\n",
    "..\n",
    "for (j = 0; j < blockSize; j++) \n",
    "    for (k = 0; k < blockSize; k+4){\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + 0] * B_trans[bj + j][bk + 0];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + 1] * B_trans[bj + j][bk + 1];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + 2] * B_trans[bj + j][bk + 2];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + 3] * B_trans[bj + j][bk + 3];\n",
    "    }\n",
    "..\n",
    "\n",
    "```\n",
    "\n",
    "However, our testing shows that this barely gives any performace advantage. Neither did unrolling 8 instrctions.\n",
    "\n",
    "The problem is that we are still using the if statement, so the best scenario would be to unroll all the instrucions and remove the if statement.\n",
    "\n",
    "the innest most loop runs up to blocksize, meaning there would be the same amount of instrcionts as the block size, so we need to unroll 16 instrucions\n",
    "to be able to remove the if statement\n",
    "\n",
    "```cpp\n",
    "..\n",
    "for (j = 0; j < blockSize; j++) {\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k] * B_trans[bj + j][bk + k];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 1] * B_trans[bj + j][bk + k + 1];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 2] * B_trans[bj + j][bk + k + 2];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 3] * B_trans[bj + j][bk + k + 3];\n",
    "\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 4] * B_trans[bj + j][bk + k + 4];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 5] * B_trans[bj + j][bk + k + 5];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 6] * B_trans[bj + j][bk + k + 6];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 7] * B_trans[bj + j][bk + k + 7];\n",
    "\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 8] * B_trans[bj + j][bk + k + 8];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 9] * B_trans[bj + j][bk + k + 9];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 10] * B_trans[bj + j][bk + k + 10];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 11] * B_trans[bj + j][bk + k + 11];\n",
    "\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 12] * B_trans[bj + j][bk + k + 12];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 13] * B_trans[bj + j][bk + k + 13];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 14] * B_trans[bj + j][bk + k + 14];\n",
    "        C[bi + i][bj + j] += A[bi + i][bk + k + 15] * B_trans[bj + j][bk + k + 15];\n",
    "    }\n",
    "..\n",
    "\n",
    "```\n",
    "Suprising, this also gave us very little performace advantage, so we played aroudn with the block size and found that a blocksize of 4 (corresponding to 4 unrooled instrctions) gives the best performace\n",
    "\n",
    "Final loop:\n",
    "\n",
    "```cpp\n",
    "..\n",
    "for (j = 0; j < blockSize; j++) {\n",
    "    // Fully unrolled for blockSize = 4\n",
    "    C[bi + i][bj + j] += A[bi + i][bk + 0] * B_trans[bj + j][bk + 0];\n",
    "    C[bi + i][bj + j] += A[bi + i][bk + 1] * B_trans[bj + j][bk + 1];\n",
    "    C[bi + i][bj + j] += A[bi + i][bk + 2] * B_trans[bj + j][bk + 2];\n",
    "    C[bi + i][bj + j] += A[bi + i][bk + 3] * B_trans[bj + j][bk + 3];\n",
    "}\n",
    "..\n",
    "\n",
    "```\n",
    "\n",
    "average gflops: 299.380005\n",
    "N = 2048\n",
    "\n",
    "Very good but not as good as numpty 32byte arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apple accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembly level instructions (AMX, NEON, gcc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "| Description                              | Matrix Size | FLOP/s\n",
    "|------------------------------------------|-------------|----------------\n",
    "| Python without numpy                     | 256         | 0.0092 GFLOPS \n",
    "| st_np_matmul.py                          | 512         | 15.374713 GFLOPS\n",
    "| st_PTB64.cpp                             | 1024        | 17.178770 GFLOPS\n",
    "| np_matmul.py                             | 1024         | 52.210830 GFLOPS\n",
    "| matrix_mult.cpp                          | 1024        | 34.398815 GFLOPS\n",
    "| st_PTB1D.cpp                             | 1024        | 31.425362 GFLOPS\n",
    "| st_PTB16.cpp                               | 1024        | 40.412571 GFLOPS\n",
    "| PTB1D.cpp                                | 1024        | 127.062523 GFLOPS\n",
    "| PTB4.cpp                                 | 1024        | 101.024773 GFLOPS\n",
    "| PTB8.cpp                                 | 1024        | 63.231953 GFLOPS\n",
    "| PTB16.cpp                                | 2048        | 194.324829 GFLOPS\n",
    "| PTB32.cpp                                | 1024        | 94.407333 GFLOPS\n",
    "| PTBunroll.cpp                                | 2048        | GFLOPS: 296.469116\n",
    " \n",
    "\n",
    "| accelerate.cpp                           | 8192        | 1326.189209 GFLOPS\n",
    "\n",
    "\n",
    "(blocksize over 16 make yields less FLOPs)\n",
    "(-O3 is faster than -O2 for me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "Run the best code\n",
    "`clang++ PTB.cpp -O3 -march=native -ffast-math -Xpreprocessor -fopenmp -I/opt/homebrew/include -L/opt/homebrew/lib -lomp -o compiled/PTB && ./compiled/PTB`\n",
    "\n",
    "\n",
    "Accelerate\n",
    "\n",
    "`clang++ -O3 -DACCELRATE_NEW_LAPACK -DACCELERATE_LAPACK_ILP64 accelerate.cpp -framework Accelerate -o ./compiled/accelerate && ./compiled/accelerate`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Questions\n",
    "\n",
    "Blocking helps with cache, but why? same with unrolling \n",
    "\n",
    "#pragma omp parallel for private(bj, bk, i, j, k) shared(A, B_trans, C) - what does this do *exacly*? why is bi not included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sources\n",
    "\n",
    "Blocking\n",
    "- https://gist.github.com/metallurgix/8ee5262ed818730b5cc0\n",
    "\n",
    "\n",
    "\n",
    "George Hotz\n",
    "- (add yt video link)\n",
    "\n",
    "\n",
    "Miduem Article\n",
    "- https://vaibhaw-vipul.medium.com/matrix-multiplication-optimizing-the-code-from-6-hours-to-1-sec-70889d33dcfa\n",
    "\n",
    "\n",
    "Neon Arm Instructions\n",
    "- https://developer.arm.com/architectures/instruction-sets/intrinsics/#f:@navigationhierarchiessimdisa=[Neon]&f:@navigationhierarchiesreturnbasetype=[float]&f:@navigationhierarchieselementbitsize=[32]&q=vld1\n",
    "\n",
    "\n",
    "Apple Accelerate\n",
    "- https://developer.apple.com/documentation/accelerate/vdsp-library\n",
    "\n",
    "\n",
    "- AMX\n",
    "- https://zhen8838.github.io/2024/04/23/mac-amx_en/\n",
    "\n",
    "\n",
    "Loop unrolling\n",
    "- https://en.wikipedia.org/wiki/Loop_unrolling#:~:text=Loop%20unrolling%2C%20also%20known%20as,or%20by%20an%20optimizing%20compiler.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
